{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy Consumption Analysis for 15-minute Interval Data\n",
    "\n",
    "This notebook provides a comprehensive analysis of energy consumption data that is recorded at 15-minute intervals. Our goal is to derive meaningful insights from the data and answer specific questions related to energy usage patterns.\n",
    "\n",
    "**Key Objectives:**\n",
    "1. Determine annual energy consumption.\n",
    "2. Calculate the annual cost based on a given electricity price per kWh.\n",
    "3. Analyze daily consumption patterns and monthly breakdowns.\n",
    "4. Study consumption differences across days of the week.\n",
    "5. Examine intra-day consumption distribution.\n",
    "6. Identify days with peak consumption at 15-minute intervals.\n",
    "7. Highlight the top 5 days with the highest instantaneous power usage.\n",
    "8. Create a histogram to visualize quarterly consumption values relative to the total.\n",
    "9. Compare solar panel production against consumption.\n",
    "10. Optimize and understand car charger energy consumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beginning the Analysis\n",
    "\n",
    "In this analysis, we examine the energy consumption data from multiple meters. The dataset provides consumption values in 15-minute intervals. Our goal is to preprocess this data and derive valuable insights from various perspectives, such as annual, daily, and intra-day consumption patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the Environment\n",
    "\n",
    "To ensure our analysis runs smoothly, we've taken the following steps:\n",
    "\n",
    "**Created a Virtual Environment:** This helps to keep our project dependencies separate from other Python projects. By using a virtual environment, we ensure that our project runs consistently across different setups.\n",
    "\n",
    "**Installed Necessary Libraries:** Our project leverages several Python libraries that aid in data manipulation, visualization, and analysis. These libraries have been automatically installed in the virtual environment to guarantee the reproducibility of our analysis.\n",
    "\n",
    "**Imported Libraries:** The required libraries for this notebook have been imported upfront to streamline the analysis process. These libraries provide a variety of functions and tools essential for our tasks.\n",
    "\n",
    "**Importing Custom Utility Functions:** To modularize our analysis and promote code reusability, we've defined custom functions in separate Python files. In this section, we'll import these utility functions to be used throughout our notebook.\n",
    "\n",
    "**Loaded Configuration:** Constants and configurations, such as file paths and threshold values, are sourced from a .env file. This approach promotes better code management and security\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activating the Virtual Environment\n",
    "\n",
    "Once you've set up the project with Poetry, you can activate the virtual environment across any operating system using the following command:\n",
    "\n",
    "```bash\n",
    "poetry shell\n",
    "```\n",
    "\n",
    "This command will start a new shell session with the virtual environment activated. All the dependencies installed via Poetry will be available in this shell session.\n",
    "\n",
    "Then you have to install Jupyter Kernel for the virtual environment:\n",
    "\n",
    "```bash\n",
    "python -m ipykernel install --user --name=zengrid-analysis-poetry\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------\n",
    "# SETTING UP .ENV FILE\n",
    "# ---------------\n",
    "# This cell is used to set up the .env file for the consumption analysis.\n",
    "\n",
    "# Import the function to create the .env file\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../..')  # This moves one directory up from 'notebooks' to the root.\n",
    "import src, utils\n",
    "\n",
    "\n",
    "# Constants for column endings\n",
    "SOLAR_PANEL_SUFFIX = \"/PV\"\n",
    "ELECTRIC_CAR_CHARGER_SUFFIX = \"/ECC\"\n",
    "BATTERY_SUFFIX = \"/BAT\"\n",
    "\n",
    "# Setting default values for .env file, you can modify here or in the .env file\n",
    "SOURCE_FILE_PATH = \"YOUR_FILE_PATH_HERE\"\n",
    "PRICE_PER_KWH = 0.000\n",
    "# The threshold for outliers is the number of standard deviations from the mean\n",
    "THRESHOLD_FOR_OUTLIERS = 1.5\n",
    "\n",
    "# If you want to force the creation of the .env file, set FORCE_CREATE to True, default is False\n",
    "FORCE_CREATE = False\n",
    "\n",
    "# Create the .env file\n",
    "src.create_dotenv_file_cons_analysis(FORCE_CREATE, SOLAR_PANEL_SUFFIX, ELECTRIC_CAR_CHARGER_SUFFIX, BATTERY_SUFFIX, SOURCE_FILE_PATH, PRICE_PER_KWH, THRESHOLD_FOR_OUTLIERS)\n",
    "\n",
    "\n",
    "# TODO: Add currency\n",
    "# TODO: Add RoI, price for solar panels, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------\n",
    "# IMPORTING LIBRARIES\n",
    "# ---------------\n",
    "# Importing all the necessary libraries required for our analysis.\n",
    "\n",
    "# Standard Libraries\n",
    "import os\n",
    "import calendar\n",
    "import re\n",
    "\n",
    "# Third-party Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Importing utility functions for data processing and analysis\n",
    "from utils import data_utils as du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------\n",
    "# LOADING CONSTANTS FROM .ENV\n",
    "# ---------------\n",
    "# Loading constants and configurations stored in the .env file.\n",
    "# BEFORE THIS STEP MODIFY THE .env FILE WITH YOUR OWN VALUES\n",
    "\n",
    "# Load values from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Define suffixes\n",
    "SOLAR_PANEL_SUFFIX = os.getenv('SOLAR_PANEL_SUFFIX', '/PV')  # default value if not found\n",
    "ELECTRIC_CAR_CHARGER_SUFFIX = os.getenv('ELECTRIC_CAR_CHARGER_SUFFIX', '/ECC')  # default value if not found\n",
    "BATTERY_SUFFIX = os.getenv('BATTERY_SUFFIX', '/BAT')  # default value if not found\n",
    "\n",
    "# Define constants\n",
    "SOURCE_FILE_PATH = os.getenv('SOURCE_FILE_PATH', 'FILE_PATH_HERE')  # default path if not found\n",
    "PRICE_PER_KWH = float(os.getenv('PRICE_PER_KWH', '183.5'))  # default value if not found\n",
    "THRESHOLD_FOR_OUTLIERS = float(os.getenv('THRESHOLD_FOR_OUTLIERS', '1.5'))  # default value if not found\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "The raw dataset contains date-time information in a non-standard format. In this step:\n",
    "\n",
    "1. The dataset is loaded into a DataFrame.\n",
    "2. A new DataFrame is created to hold the processed data.\n",
    "3. The combined date-time column is split into separate date, start time, and end time values.\n",
    "4. These separated values are then used to create two new columns: TimePeriodStart and TimePeriodEnd, which represent the start and end of each 15-minute interval in a standard datetime format.\n",
    "5. The original combined date-time column is dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time_Slice</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total, kWh</td>\n",
       "      <td>523.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A01</td>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A02</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A03</td>\n",
       "      <td>2.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>A91</td>\n",
       "      <td>3.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>A92</td>\n",
       "      <td>3.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>A93</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>A94</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>A95</td>\n",
       "      <td>2.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Time_Slice   Value\n",
       "0   Total, kWh  523.95\n",
       "0          A00    2.10\n",
       "1          A01    2.40\n",
       "2          A02    2.10\n",
       "3          A03    2.25\n",
       "..         ...     ...\n",
       "91         A91    3.15\n",
       "92         A92    3.15\n",
       "93         A93    3.00\n",
       "94         A94    3.00\n",
       "95         A95    2.70\n",
       "\n",
       "[97 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SOURCE_FILE_PATH_test = (r'D:\\Letöltések\\SAP_ITS_CSV_letoltes202309011.csv').lower()\n",
    "\n",
    "# Define the mapping between file extensions and their respective pandas read functions\n",
    "def read_data_file(file_path, **kwargs):\n",
    "    \"\"\"\n",
    "    Read a data file into a pandas DataFrame based on its extension.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): Path to the data file.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: The data loaded into a pandas DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    extension_read_function_mapping = {\n",
    "        ## Modified the CSV because of the EON-specific format\n",
    "        \".csv\": read_csv_auto_delimiter,\n",
    "        \".xlsx\": pd.read_excel,\n",
    "        \".xls\": pd.read_excel,\n",
    "        \".tsv\": lambda x, **y: pd.read_csv(x, delimiter=\"\\t\", **y),\n",
    "        \".json\": pd.read_json,\n",
    "        \".parquet\": pd.read_parquet,\n",
    "        \".feather\": pd.read_feather,\n",
    "        \".dta\": pd.read_stata,\n",
    "        \".pkl\": pd.read_pickle,\n",
    "        \".sas7bdat\": pd.read_sas,\n",
    "    }\n",
    "\n",
    "    _, file_extension = os.path.splitext(file_path)\n",
    "\n",
    "    read_function = extension_read_function_mapping.get(file_extension)\n",
    "\n",
    "    if read_function is None:\n",
    "        raise ValueError(f\"Unsupported file extension: {file_extension}.\")\n",
    "\n",
    "    # Remove the sep argument if it exists, as it's handled internally for CSVs\n",
    "    kwargs.pop(\"sep\", None)\n",
    "    return read_function(file_path, **kwargs)\n",
    "\n",
    "\n",
    "# Automatically determines the delimiter for CSV files\n",
    "def read_csv_auto_delimiter(filepath, **kwargs):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\", errors=\"ignore\") as file:\n",
    "        first_line = file.readline()\n",
    "        if \";\" in first_line:\n",
    "            delimiter = \";\"\n",
    "        else:\n",
    "            delimiter = \",\"\n",
    "        return pd.read_csv(filepath, sep=delimiter, **kwargs)\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# DATA TRANSFORMATION UTILITIES\n",
    "# -----------------------\n",
    "\n",
    "\n",
    "# Reshapes the DataFrame to the desired format\n",
    "def eon_dataframe(df):\n",
    "    # Filter rows where \"Mertekegys\" column is \"kWh\"\n",
    "    df_filtered = df[df[\"Mertekegys\"] == \"kWh\"]\n",
    "\n",
    "    # Drop columns \"SXX\", \"OBIS\", and \"Szorzo\"\n",
    "    columns_to_drop = [\n",
    "        col\n",
    "        for col in df_filtered.columns\n",
    "        if col.startswith(\"S\") or col in [\"OBIS\", \"Szorzo\", \"Mertekegys\"]\n",
    "    ]\n",
    "    df_filtered = df_filtered.drop(columns=columns_to_drop)\n",
    "\n",
    "    # Convert \"Datum\" column to datetime format\n",
    "    df_filtered[\"Datum\"] = pd.to_datetime(df_filtered[\"Datum\"])\n",
    "\n",
    "    # Fetch columns that start with \"A\" and contain at least one non-NaN value\n",
    "    value_columns = [col for col in df_filtered.columns if col.startswith(\"A\") and not df_filtered[col].isna().all()]\n",
    "\n",
    "    # Melt the dataframe\n",
    "    melted_df = df_filtered.melt(\n",
    "        id_vars=[\"MP\", \"Datum\"],\n",
    "        value_vars=value_columns,\n",
    "        var_name=\"Time_Slice\",\n",
    "        value_name=\"Value\",\n",
    "    )\n",
    "\n",
    "    # Create a function to generate the time interval based on the AXX value\n",
    "    def get_time_interval(slice_value, datum):\n",
    "        num = int(slice_value[1:])\n",
    "        start_time = pd.Timedelta(minutes=15 * num)\n",
    "        end_time = start_time + pd.Timedelta(minutes=15)\n",
    "        return f\"{datum.strftime('%Y.%m.%d')} {start_time} - {end_time}\"\n",
    "\n",
    "    # Remove \"0 days\" and \"1 days\" from the `Time_Slice` column\n",
    "    melted_df[\"Time_Slice\"] = melted_df[\"Time_Slice\"].str.replace(r\"\\d+ days \", \"\")\n",
    "\n",
    "    # Pivot the melted DataFrame\n",
    "    result_df = melted_df.pivot_table(index=\"Time_Slice\", values=\"Value\", aggfunc=\"first\").reset_index()\n",
    "\n",
    "    # Add the \"Total, kWh\" row\n",
    "    total_kwh = result_df[\"Value\"].sum()\n",
    "    total_row = pd.DataFrame({'Time_Slice': ['Total, kWh'], 'Value': [total_kwh]})\n",
    "\n",
    "    # Concatenate the total row with the result DataFrame\n",
    "    result_df = pd.concat([total_row, result_df])\n",
    "    result_df.head(100)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "\n",
    "# Load and preprocess the data based on file type\n",
    "def load_and_preprocess_data(SOURCE_FILE_PATH):\n",
    "    # Task1: Load the data using the defined function based on file type\n",
    "    if SOURCE_FILE_PATH.endswith(\".csv\"):\n",
    "        data = read_data_file(SOURCE_FILE_PATH)\n",
    "    else:\n",
    "        data = read_data_file(SOURCE_FILE_PATH, skiprows=[1])\n",
    "\n",
    "    # Task 2: Preprocessing\n",
    "    # Check the file extension\n",
    "    if SOURCE_FILE_PATH.endswith(\".csv\"):\n",
    "        processed_data = eon_dataframe(data)\n",
    "    else:\n",
    "        processed_data = data.copy()\n",
    "\n",
    "    return processed_data\n",
    "\n",
    "# TEST\n",
    "load_and_preprocess_data(SOURCE_FILE_PATH_test)\n",
    "\n",
    "# Task1: Load the data using the defined function\n",
    "# processed_data = du.load_and_preprocess_data(SOURCE_FILE_PATH_test)\n",
    "\n",
    "# processed_data.head(98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unsupported file extension: .",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Repos\\zengrid-analysis\\notebooks\\cons-analysis\\cons-analysis-dyn.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Repos/zengrid-analysis/notebooks/cons-analysis/cons-analysis-dyn.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Task1: Load and preprocess the data using the defined function\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Repos/zengrid-analysis/notebooks/cons-analysis/cons-analysis-dyn.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m processed_data \u001b[39m=\u001b[39m du\u001b[39m.\u001b[39;49mload_and_preprocess_data(SOURCE_FILE_PATH)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Repos/zengrid-analysis/notebooks/cons-analysis/cons-analysis-dyn.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Extracting date, start time, and end time from 'Időszeletek'\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Repos/zengrid-analysis/notebooks/cons-analysis/cons-analysis-dyn.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m date \u001b[39m=\u001b[39m processed_data[\u001b[39m'\u001b[39m\u001b[39mIdőszeletek\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mstr[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32md:\\Repos\\zengrid-analysis\\notebooks\\cons-analysis\\../..\\utils\\data_utils.py:169\u001b[0m, in \u001b[0;36mload_and_preprocess_data\u001b[1;34m(SOURCE_FILE_PATH)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_and_preprocess_data\u001b[39m(SOURCE_FILE_PATH):\n\u001b[0;32m    168\u001b[0m     \u001b[39m# Task1: Load the data using the defined function based on file type\u001b[39;00m\n\u001b[1;32m--> 169\u001b[0m     \u001b[39mif\u001b[39;00m SOURCE_FILE_PATH\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    170\u001b[0m         data \u001b[39m=\u001b[39m read_data_file(SOURCE_FILE_PATH, skiprows\u001b[39m=\u001b[39m[\u001b[39m1\u001b[39m])\n\u001b[0;32m    171\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Repos\\zengrid-analysis\\notebooks\\cons-analysis\\../..\\utils\\data_utils.py:76\u001b[0m, in \u001b[0;36mread_data_file\u001b[1;34m(file_path, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m read_function \u001b[39m=\u001b[39m extension_read_function_mapping\u001b[39m.\u001b[39mget(file_extension)\n\u001b[0;32m     75\u001b[0m \u001b[39mif\u001b[39;00m read_function \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnsupported file extension: \u001b[39m\u001b[39m{\u001b[39;00mfile_extension\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     78\u001b[0m \u001b[39m# Remove the sep argument if it exists, as it's handled internally for CSVs\u001b[39;00m\n\u001b[0;32m     79\u001b[0m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39msep\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[1;31mValueError\u001b[0m: Unsupported file extension: ."
     ]
    }
   ],
   "source": [
    "# Task1: Load and preprocess the data using the defined function\n",
    "processed_data = du.load_and_preprocess_data(SOURCE_FILE_PATH)\n",
    "\n",
    "# Extracting date, start time, and end time from 'Időszeletek'\n",
    "date = processed_data['Időszeletek'].str.split(' ').str[0]\n",
    "start_time = processed_data['Időszeletek'].str.split(' - ').str[0].str.split(' ').str[1]\n",
    "end_time = processed_data['Időszeletek'].str.split(' - ').str[1]\n",
    "\n",
    "processed_data['TimePeriodStart'] = date + ' ' + start_time\n",
    "processed_data['TimePeriodEnd'] = date + ' ' + end_time\n",
    "\n",
    "# Adjust for '24:00' in TimePeriodEnd\n",
    "mask_24 = processed_data['TimePeriodEnd'].str.endswith('24:00')\n",
    "processed_data.loc[mask_24, 'TimePeriodEnd'] = (pd.to_datetime(processed_data.loc[mask_24, 'TimePeriodEnd'].str.split(' ').str[0]) + pd.Timedelta(days=1)).dt.strftime('%Y.%m.%d') + ' 00:00'\n",
    "\n",
    "processed_data['TimePeriodStart'] = pd.to_datetime(processed_data['TimePeriodStart'], format='%Y.%m.%d %H:%M')\n",
    "processed_data['TimePeriodEnd'] = pd.to_datetime(processed_data['TimePeriodEnd'], format='%Y.%m.%d %H:%M')\n",
    "\n",
    "processed_data.drop('Időszeletek', axis=1, inplace=True)\n",
    "\n",
    "# Replace NaN values with 0\n",
    "processed_data.fillna(0, inplace=True)\n",
    "\n",
    "# Extracting DayOfWeek, Month, Hour, and Minute from 'TimePeriodStart'\n",
    "processed_data['DayOfWeek'] = processed_data['TimePeriodStart'].dt.dayofweek\n",
    "processed_data['Month'] = processed_data['TimePeriodStart'].dt.month\n",
    "processed_data['Hour'] = processed_data['TimePeriodStart'].dt.hour\n",
    "processed_data['Minute'] = processed_data['TimePeriodStart'].dt.minute\n",
    "\n",
    "# Task 3: Distinguish between different meters\n",
    "consumption_meter_columns = [col for col in processed_data.columns if SOLAR_PANEL_SUFFIX not in col and ELECTRIC_CAR_CHARGER_SUFFIX not in col and BATTERY_SUFFIX not in col and 'TimePeriod' not in col and col != 'DayOfWeek' and col != 'Month' and col != 'Hour' and col != 'Minute']\n",
    "solar_panel_columns = [col for col in processed_data.columns if SOLAR_PANEL_SUFFIX in col]\n",
    "electric_car_charger_columns = [col for col in processed_data.columns if ELECTRIC_CAR_CHARGER_SUFFIX in col]\n",
    "battery_columns = [col for col in processed_data.columns if BATTERY_SUFFIX in col]\n",
    "\n",
    "# Creating \"Pods\" dictionary, \"Pods\" are the pair of Consumption Meters and Solar Panels, not every Consumption Meter has a Solar Panel\n",
    "pods = {}\n",
    "\n",
    "for meter in consumption_meter_columns:\n",
    "    solar_panel = meter + SOLAR_PANEL_SUFFIX\n",
    "    if solar_panel in solar_panel_columns:\n",
    "        pods[meter] = (meter, solar_panel)\n",
    "    else:\n",
    "        pods[meter] = (meter, None)\n",
    "\n",
    "\n",
    "# Display the processed data and its types\n",
    "processed_data.head(), processed_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the pods\n",
    "for meter, solar_panel in pods.items():\n",
    "    if solar_panel:\n",
    "        print(f\"Pod: {meter} with Solar Panel: {solar_panel}\")\n",
    "    else:\n",
    "        print(f\"Pod: {meter} without Solar Panel\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Calculate annual consumption\n",
    "This task involves understanding the annual consumption of each meter and calculating associated costs:\n",
    "\n",
    "1. The annual consumption for each meter is computed by summing up its respective values.\n",
    "2. The annual cost for each meter is derived using a given price per kWh.\n",
    "3. Average daily consumption is computed for each 15-minute interval throughout the entire year.\n",
    "4. Average monthly consumption is calculated for each 15-minute interval, grouped by month.\n",
    "5. A visualization is created to showcase the average consumption per hour throughout the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate annual consumption for each type of meter\n",
    "annual_consumption = processed_data[consumption_meter_columns].sum()\n",
    "\n",
    "# Step 2: Calculate annual costs\n",
    "annual_costs = annual_consumption * PRICE_PER_KWH\n",
    "\n",
    "# Step 3: Average daily consumption for each 15-minute interval is already done in preprocessing\n",
    "# We have 'Hour' and 'Minute' columns created in the preprocessing step.\n",
    "avg_daily_consumption = processed_data.groupby(['Hour', 'Minute']).mean().reset_index()\n",
    "\n",
    "# Step 4: Average daily consumption for each 15-minute interval grouped by month\n",
    "# 'Month' column was also created during preprocessing.\n",
    "avg_monthly_consumption = processed_data.groupby(['Month', 'Hour', 'Minute']).mean().reset_index()\n",
    "\n",
    "# Generating time column for plotting\n",
    "avg_monthly_consumption['Time'] = avg_monthly_consumption['Hour'].astype(str).str.zfill(2) + ':' + avg_monthly_consumption['Minute'].astype(str).str.zfill(2)\n",
    "avg_monthly_consumption['PlotTime'] = pd.to_datetime('2000-01-01 ' + avg_monthly_consumption['Time'])\n",
    "\n",
    "# Calculate total consumption across all consumption meters and electric car chargers\n",
    "avg_monthly_consumption['TotalConsumption'] = avg_monthly_consumption[consumption_meter_columns + electric_car_charger_columns].sum(axis=1)\n",
    "\n",
    "# Calculate the difference contributed by the solar panels\n",
    "avg_monthly_consumption['SolarContribution'] = avg_monthly_consumption[solar_panel_columns].sum(axis=1)\n",
    "\n",
    "# Calculate net consumption (total consumption minus solar panel production)\n",
    "avg_monthly_consumption['NetConsumption'] = avg_monthly_consumption['TotalConsumption'] - avg_monthly_consumption['SolarContribution']\n",
    "\n",
    "# Define the color palette\n",
    "palette = sns.color_palette(\"tab20\", 12)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(14, 18))\n",
    "\n",
    "# Plotting Total Consumption\n",
    "for month, color in zip(avg_monthly_consumption['Month'].unique(), palette):\n",
    "    monthly_data = avg_monthly_consumption[avg_monthly_consumption['Month'] == month]\n",
    "    ax1.plot(monthly_data['PlotTime'], monthly_data['TotalConsumption'], label=calendar.month_name[month], color=color)\n",
    "ax1.set_title(\"Total Consumption per Hour throughout the Year\")\n",
    "ax1.set_ylabel(\"Average Consumption (kWh)\")\n",
    "ax1.legend()\n",
    "\n",
    "# Plotting Solar Panel Contribution\n",
    "for month, color in zip(avg_monthly_consumption['Month'].unique(), palette):\n",
    "    monthly_data = avg_monthly_consumption[avg_monthly_consumption['Month'] == month]\n",
    "    ax2.plot(monthly_data['PlotTime'], monthly_data['SolarContribution'], label=calendar.month_name[month], color=color)\n",
    "ax2.set_title(\"Solar Panel Contribution per Hour throughout the Year\")\n",
    "ax2.set_xlabel(\"Hour of Day\")\n",
    "ax2.set_ylabel(\"Average Solar Contribution (kWh)\")\n",
    "ax2.legend()\n",
    "\n",
    "# Plotting Net Consumption\n",
    "for month, color in zip(avg_monthly_consumption['Month'].unique(), palette):\n",
    "    monthly_data = avg_monthly_consumption[avg_monthly_consumption['Month'] == month]\n",
    "    ax3.plot(monthly_data['PlotTime'], monthly_data['NetConsumption'], label=calendar.month_name[month], color=color)\n",
    "ax3.set_title(\"Net Consumption (after solar contribution) per Hour throughout the Year\")\n",
    "ax3.set_ylabel(\"Average Net Consumption (kWh)\")\n",
    "ax3.legend()\n",
    "\n",
    "# Formatting axes\n",
    "for ax in [ax1, ax2, ax3]:\n",
    "    ax.xaxis.set_major_locator(mdates.HourLocator(interval=1))\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%H'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Daily Consumption Patterns and Monthly Breakdowns\n",
    "\n",
    "This task aims to identify patterns in consumption across different days of the week:\n",
    "\n",
    "1. Average consumption values for each day of the week are computed.\n",
    "2. A bar chart is created to showcase the average consumption for each day, from Monday to Sunday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include car chargers in the consumption columns\n",
    "electric_car_charger_columns = [col for col in processed_data.columns if 'ECC' in col]\n",
    "all_consumption_columns = consumption_meter_columns + electric_car_charger_columns\n",
    "\n",
    "# Calculate average consumption for the days of the week for each month\n",
    "processed_data['DayOfWeek'] = processed_data['TimePeriodStart'].dt.dayofweek\n",
    "avg_weekly_monthly_consumption = processed_data.groupby(['Month', 'DayOfWeek']).mean()[all_consumption_columns].reset_index()\n",
    "\n",
    "# Convert numerical day representation to actual day names\n",
    "avg_weekly_monthly_consumption['DayOfWeekName'] = avg_weekly_monthly_consumption['DayOfWeek'].apply(lambda x: calendar.day_name[x])\n",
    "\n",
    "# Visualization with Enhancements\n",
    "fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(20, 15), sharex=True, sharey=True)\n",
    "days_order = list(calendar.day_name)\n",
    "\n",
    "for month in range(1, 13):\n",
    "    ax = axes[(month-1) // 4][(month-1) % 4]\n",
    "    \n",
    "    monthly_data = avg_weekly_monthly_consumption[avg_weekly_monthly_consumption['Month'] == month]\n",
    "    \n",
    "    bars = []\n",
    "    for column in all_consumption_columns:\n",
    "        bars.append(ax.bar(monthly_data['DayOfWeekName'], monthly_data[column], label=column, alpha=0.7))\n",
    "    \n",
    "    # Set bar labels\n",
    "    for bar_set in bars:\n",
    "        for bar in bar_set:\n",
    "            yval = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2, yval + 0.1, round(yval,2), ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    ax.set_title(calendar.month_name[month])\n",
    "    ax.set_xticks(list(range(7)))  # Set x-ticks for every day\n",
    "    ax.set_xticklabels(days_order, rotation=45, ha='right')  \n",
    "    ax.grid(axis='y')\n",
    "    ax.set_ylabel('Avg Consumption (kWh)')\n",
    "\n",
    "# Add a legend to the figure\n",
    "fig.legend(all_consumption_columns, loc='upper center', bbox_to_anchor=(0.5, 1.05), ncol=len(all_consumption_columns))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract day of the week\n",
    "processed_data['DayOfWeek'] = processed_data['TimePeriodStart'].dt.dayofweek\n",
    "\n",
    "# Calculate average consumption for the days of the week\n",
    "avg_weekly_consumption = processed_data.groupby('DayOfWeek').mean().reset_index()\n",
    "\n",
    "# Convert numerical day representation to actual day names\n",
    "avg_weekly_consumption['DayOfWeek'] = avg_weekly_consumption['DayOfWeek'].apply(lambda x: calendar.day_name[x])\n",
    "\n",
    "# Visualization of average consumption across the days of the week\n",
    "days_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "avg_weekday_consumption = avg_weekly_consumption.set_index('DayOfWeek').reindex(days_order).reset_index()\n",
    "\n",
    "# Set up plotting parameters\n",
    "width = 0.2\n",
    "x = np.arange(len(days_order))\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "bar_colors = sns.color_palette(\"tab10\", len(all_consumption_columns))\n",
    "for idx, (column, color) in enumerate(zip(all_consumption_columns, bar_colors), 1):\n",
    "    plt.bar(x - width * len(all_consumption_columns) / 2 + idx * width, avg_weekday_consumption[column], width, label=column, color=color)\n",
    "\n",
    "# Set labels, title, and custom x-axis tick labels\n",
    "plt.ylabel('Average Consumption (kWh)')\n",
    "plt.xlabel('Day of the Week')\n",
    "plt.title('Average Consumption per Day of the Week (2022)')\n",
    "plt.xticks(x, days_order)\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Examining Intra-day Consumption Distribution\n",
    "\n",
    "This task delves into the consumption patterns within a day:\n",
    "\n",
    "1. The data is grouped by hours and minutes to determine the average consumption for each 15-minute interval throughout the day.\n",
    "2. A line plot is created to show the intra-day distribution of average consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate average consumption for each 15-minute interval of the day\n",
    "\n",
    "# As we have already extracted 'Hour' and 'Minute' in the preprocessing step, we can directly compute the average.\n",
    "avg_intra_day = processed_data.groupby(['Hour', 'Minute']).mean()[all_consumption_columns].reset_index()\n",
    "\n",
    "# Convert 'Hour' and 'Minute' to a time format for better visualization\n",
    "avg_intra_day['Time'] = avg_intra_day['Hour'].astype(str).str.zfill(2) + ':' + avg_intra_day['Minute'].astype(str).str.zfill(2)\n",
    "\n",
    "# Step 2: Visualization of intra-day consumption patterns\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "# Plot data for each consumption column\n",
    "for column in all_consumption_columns:\n",
    "    plt.plot(avg_intra_day['Time'], avg_intra_day[column], label=column, marker='o', markersize=3)\n",
    "\n",
    "# Set labels, title, and format the x-axis\n",
    "plt.xlabel('Time of Day')\n",
    "plt.ylabel('Average Consumption (kWh)')\n",
    "plt.title('Intra-day Distribution of Average Consumption (2022)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.grid(axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Identifying Days with Peak Consumption at 15-minute Intervals\n",
    "\n",
    "This task focuses on identifying periods of peak consumption:\n",
    "\n",
    "1. The data is analyzed to find the 15-minute intervals with the highest total power consumption.\n",
    "2. The top 5 unique days with the highest instantaneous power are identified.\n",
    "3. A line plot is created to show the intra-day power distribution for these top 5 unique days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Convert to kWh\n",
    "# Multiplying by 4 to convert kW readings of 15-minute intervals to kWh\n",
    "avg_intra_day[all_consumption_columns] *= 4\n",
    "\n",
    "# Step 2: Calculate total consumption for each time interval\n",
    "avg_intra_day['Total'] = avg_intra_day[all_consumption_columns].sum(axis=1)\n",
    "\n",
    "# Step 3: Identify peak consumption time\n",
    "peak_time = avg_intra_day.iloc[avg_intra_day['Total'].idxmax()]['Time']\n",
    "peak_value = avg_intra_day['Total'].max()\n",
    "\n",
    "# Step 4: Visualization\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "# Plot data for each consumption column\n",
    "for column in all_consumption_columns:\n",
    "    plt.plot(avg_intra_day['Time'], avg_intra_day[column], label=column, marker='o', markersize=3)\n",
    "\n",
    "# Highlight the peak consumption period\n",
    "plt.axvline(peak_time, color='red', linestyle='--', label=f'Peak Consumption at {peak_time}')\n",
    "plt.axhline(peak_value, color='green', linestyle='--', label=f'Peak Consumption: {peak_value:.2f} kWh')\n",
    "\n",
    "# Set labels, title, and format the x-axis\n",
    "plt.xlabel('Time of Day')\n",
    "plt.ylabel('Average Consumption (kWh)')\n",
    "plt.title('Intra-day Distribution of Average Consumption with Peak Highlighted (2022)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.grid(axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Identify the top 5 days with the highest instantaneous power.\n",
    "\n",
    "The focus of this task is to pinpoint periods of peak consumption:\n",
    "\n",
    "1. **Highlighting Peak Intervals**:\n",
    "    - The dataset is first scoured to identify the 15-minute intervals with the top 5 highest total power consumptions. It's worth noting that multiple peak values might occur on the same day. The visual representation of this data will underscore these peak values, allowing us to identify the most power-intensive moments throughout the year.\n",
    "2. **Analysis of Unique Peak Days**:\n",
    "    - To get a broader view, we delve deeper to identify the top 5 unique days that experienced the highest instantaneous power. This approach ensures we're not just looking at isolated peak intervals but rather entire days of significant power usage.\n",
    "    - A line plot is then crafted to vividly display the intra-day power distribution for each of these standout days, painting a clear picture of consumption dynamics on these particularly demanding days.\n",
    "\n",
    "By the culmination of this task, we'll have a nuanced understanding of both instantaneous power spikes and broader days of high consumption, offering a multifaceted view of peak usage periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Convert consumption to power (kW)\n",
    "# Since the data is for 15-minute intervals, we multiply by 4 to get kW\n",
    "processed_data[all_consumption_columns] *= 4\n",
    "\n",
    "# Calculate total power for each interval\n",
    "processed_data['TotalPower'] = processed_data[all_consumption_columns].sum(axis=1)\n",
    "\n",
    "# Step 2: Identify top 5 intervals with the highest power\n",
    "top_5_intervals = processed_data.nlargest(5, 'TotalPower')\n",
    "\n",
    "# Step 3: Extract unique dates from top intervals\n",
    "unique_top_dates = top_5_intervals['TimePeriodStart'].dt.date.unique()\n",
    "\n",
    "print(\"Top 5 Dates with the Highest Instantaneous Power:\")\n",
    "for date in unique_top_dates:\n",
    "    print(date)\n",
    "\n",
    "# Step 4: Visualization\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "# Plotting intra-day distribution for each unique top date\n",
    "for date in unique_top_dates:\n",
    "    subset = processed_data[processed_data['TimePeriodStart'].dt.date == date]\n",
    "    time = subset['TimePeriodStart'].dt.strftime('%H:%M')\n",
    "    plt.plot(time, subset['TotalPower'], label=str(date), marker='o', markersize=4)\n",
    "\n",
    "# Adjusting the plot\n",
    "plt.xlabel('Time of Day')\n",
    "plt.ylabel('Power (kW)')\n",
    "plt.title('Intra-day Power Distribution for Days with Highest Instantaneous Power')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate daily total power\n",
    "daily_total_power = processed_data.groupby(processed_data['TimePeriodStart'].dt.date)['TotalPower'].sum()\n",
    "\n",
    "# Get top 5 unique dates with the highest total power\n",
    "top_5_dates = daily_total_power.nlargest(5).index\n",
    "\n",
    "print(\"Top 5 Dates with the Highest Instantaneous Power:\")\n",
    "for date in top_5_dates:\n",
    "    print(date)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "# Plotting intra-day distribution for each unique top date\n",
    "for date in top_5_dates:\n",
    "    subset = processed_data[processed_data['TimePeriodStart'].dt.date == date]\n",
    "    time = subset['TimePeriodStart'].dt.strftime('%H:%M')\n",
    "    plt.plot(time, subset['TotalPower'], label=str(date), marker='o', markersize=4)\n",
    "\n",
    "# Adjusting the plot\n",
    "plt.xlabel('Time of Day')\n",
    "plt.ylabel('Power (kW)')\n",
    "plt.title('Intra-day Power Distribution for Days with Highest Instantaneous Power')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "fig, axes = plt.subplots(nrows=5, ncols=1, figsize=(16, 30))\n",
    "all_consumption_columns = consumption_meter_columns + electric_car_charger_columns\n",
    "\n",
    "for idx, date in enumerate(top_5_dates):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Subset for the date\n",
    "    subset = processed_data[processed_data['TimePeriodStart'].dt.date == date]\n",
    "    \n",
    "    # Extract data for each consumption column and stack them\n",
    "    bar_data = [subset[col].values for col in all_consumption_columns]\n",
    "    cum_data = np.cumsum(bar_data, axis=0)\n",
    "    \n",
    "    for i, col in enumerate(all_consumption_columns):\n",
    "        if i == 0:\n",
    "            ax.bar(subset['TimePeriodStart'].dt.strftime('%H:%M'), bar_data[i], label=col)\n",
    "        else:\n",
    "            ax.bar(subset['TimePeriodStart'].dt.strftime('%H:%M'), bar_data[i], bottom=cum_data[i - 1], label=col)\n",
    "    \n",
    "    # Adjusting the subplot\n",
    "    ax.set_title(f'Intra-day Power Distribution for {date}')\n",
    "    ax.set_xlabel('Time of Day')\n",
    "    ax.set_ylabel('Power (kW)')\n",
    "    time_labels = subset['TimePeriodStart'].dt.strftime('%H:%M')\n",
    "    ax.set_xticks(np.arange(len(time_labels)))\n",
    "    ax.set_xticklabels(time_labels, rotation=45)\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dates of interest\n",
    "dates_of_interest = ['2022-01-24', '2022-07-04']\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(nrows=len(dates_of_interest), ncols=1, figsize=(16, 15))  # Adjusted the figure size\n",
    "\n",
    "for idx, date in enumerate(dates_of_interest):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Subset for the date\n",
    "    subset = processed_data[processed_data['TimePeriodStart'].dt.date == pd.to_datetime(date).date()]\n",
    "    \n",
    "    # Extract data for each consumption column and stack them\n",
    "    bar_data = [subset[col].values for col in all_consumption_columns]\n",
    "    cum_data = np.cumsum(bar_data, axis=0)\n",
    "    \n",
    "    for i, col in enumerate(all_consumption_columns):\n",
    "        if i == 0:\n",
    "            ax.bar(subset['TimePeriodStart'].dt.strftime('%H:%M'), bar_data[i], label=col)\n",
    "        else:\n",
    "            ax.bar(subset['TimePeriodStart'].dt.strftime('%H:%M'), bar_data[i], bottom=cum_data[i - 1], label=col)\n",
    "    \n",
    "    # Adjusting the subplot\n",
    "    ax.set_title(f'Intra-day Power Distribution for {date}')\n",
    "    ax.set_xlabel('Time of Day')\n",
    "    ax.set_ylabel('Power (kW)')\n",
    "    time_labels = subset['TimePeriodStart'].dt.strftime('%H:%M')\n",
    "    ax.set_xticks(np.arange(len(time_labels)))\n",
    "    ax.set_xticklabels(time_labels, rotation=45)\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Visualizing Quarterly Consumption\n",
    "\n",
    "This task aims to understand the distribution of daily energy consumption for each meter:\n",
    "\n",
    "1. Histograms are created for each meter to show the distribution of daily energy consumption values.\n",
    "2. These histograms provide insights into the frequency of different daily consumption values for each meter, highlighting common consumption patterns and any anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the daily energy consumption for each meter\n",
    "processed_data['Date'] = processed_data['TimePeriodStart'].dt.date\n",
    "daily_consumption = processed_data.groupby('Date')[all_consumption_columns].sum()\n",
    "\n",
    "# Setting up the plotting environment\n",
    "sns.set_style(\"whitegrid\")\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(12, 15))\n",
    "\n",
    "# Plotting histograms for each meter\n",
    "for idx, column in enumerate(all_consumption_columns):\n",
    "    sns.histplot(daily_consumption[column], ax=axes[idx], bins=30, kde=True, color='skyblue', edgecolor='black')\n",
    "    \n",
    "    # Setting titles and labels for each subplot\n",
    "    axes[idx].set_title(f'Distribution of Daily Energy Consumption for {column}')\n",
    "    axes[idx].set_xlabel('Daily Energy Consumption (kWh)')\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "\n",
    "# Adjusting the layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Displaying the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8: Anomaly detection\n",
    "Here's a basic approach to detect anomalies using the interquartile range (IQR):\n",
    "\n",
    "IQR Method:\n",
    "- Calculate the first (Q1) and third quartiles (Q3) for the data.\n",
    "- Compute the IQR: IQR=Q3−Q1IQR=Q3−Q1.\n",
    "- Define a threshold for outliers, typically 1.5 times the IQR below Q1 and above Q3.\n",
    "- Data points outside of this range are considered anomalies.\n",
    "\n",
    "Let's implement this for daily energy consumption:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each meter, calculate Q1, Q3, IQR, and the bounds for outliers\n",
    "thresholds = {}\n",
    "\n",
    "for column in all_consumption_columns:\n",
    "    Q1 = daily_consumption[column].quantile(0.25)\n",
    "    Q3 = daily_consumption[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - THRESHOLD_FOR_OUTLIERS * IQR\n",
    "    upper_bound = Q3 + THRESHOLD_FOR_OUTLIERS * IQR\n",
    "    \n",
    "    thresholds[column] = {\"Lower Bound\": lower_bound, \"Upper Bound\": upper_bound}\n",
    "\n",
    "# Display thresholds for each meter\n",
    "for meter, bounds in thresholds.items():\n",
    "    print(f\"Thresholds for {meter}:\")\n",
    "    print(f\"  - Lower Bound: {bounds['Lower Bound']:.2f}\")\n",
    "    print(f\"  - Upper Bound: {bounds['Upper Bound']:.2f}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each meter, calculate Q1, Q3, IQR, and the bounds for outliers\n",
    "anomaly_dates = {}\n",
    "\n",
    "for column in all_consumption_columns:\n",
    "    Q1 = daily_consumption[column].quantile(0.25)\n",
    "    Q3 = daily_consumption[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - THRESHOLD_FOR_OUTLIERS * IQR\n",
    "    upper_bound = Q3 + THRESHOLD_FOR_OUTLIERS * IQR\n",
    "    \n",
    "    # Extract dates of the anomalies\n",
    "    anomaly_dates[column] = daily_consumption[(daily_consumption[column] < lower_bound) | (daily_consumption[column] > upper_bound)].index\n",
    "\n",
    "# Display dates of anomalies for each meter\n",
    "for meter, dates in anomaly_dates.items():\n",
    "    print(f\"Anomaly Dates for {meter}:\")\n",
    "    for date in dates:\n",
    "        print(f\"  - {date.strftime('%Y-%m-%d')}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each meter, calculate Q1, Q3, IQR, and the bounds for outliers\n",
    "anomalies = {}\n",
    "\n",
    "for column in all_consumption_columns:\n",
    "    Q1 = daily_consumption[column].quantile(0.25)\n",
    "    Q3 = daily_consumption[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - THRESHOLD_FOR_OUTLIERS * IQR\n",
    "    upper_bound = Q3 + THRESHOLD_FOR_OUTLIERS * IQR\n",
    "    \n",
    "    # Filter out the anomalies\n",
    "    anomalies[column] = daily_consumption[(daily_consumption[column] < lower_bound) | (daily_consumption[column] > upper_bound)]\n",
    "\n",
    "# Plotting the daily consumption along with anomalies\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(12, 15))\n",
    "\n",
    "for idx, column in enumerate(all_consumption_columns):\n",
    "    axes[idx].plot(daily_consumption.index, daily_consumption[column], label='Daily Consumption', color='blue')\n",
    "    axes[idx].scatter(anomalies[column].index, anomalies[column][column], color='red', label='Anomalies')\n",
    "    axes[idx].set_title(f'Daily Energy Consumption with Anomalies for {column}')\n",
    "    axes[idx].set_xlabel('Date')\n",
    "    axes[idx].set_ylabel('Daily Energy Consumption (kWh)')\n",
    "    axes[idx].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8: Solar Panel Production vs Consumption\n",
    "One of the sustainable solutions to energy needs is harnessing solar power. In this section, we'll compare solar panel production against consumption. This will provide insights into how self-produced energy matches up against consumption and where additional energy sources might be needed.\n",
    "Understanding the Problem:\n",
    "\n",
    "Often, solar panels produce more energy than is consumed by a facility or household. This excess energy, if not stored or fed back into the grid, is essentially wasted. By identifying the days and the amount of excess energy produced, facilities can make informed decisions, such as investing in energy storage solutions or adjusting their energy consumption patterns.\n",
    "Approach:\n",
    "\n",
    "To visualize and calculate the excess energy produced by the solar panels, we take the following steps:\n",
    "\n",
    "1. **Filtering Excess Intervals:**\n",
    "For each 15-minute interval in the dataset, we identify periods where the energy generated by the solar panel exceeds the energy consumed.\n",
    "    ```python\n",
    "    excess_intervals = data[data[solar_panel_col] > data[meter_col]]\n",
    "    ```\n",
    "\n",
    "2. **Calculating Excess Energy:**\n",
    "    For each of these intervals, we calculate the difference between the energy generated by the solar panel and the energy consumed. This difference represents the \"excess energy\" for that interval.\n",
    "    ```python\n",
    "    excess_intervals['Excess'] = excess_intervals[solar_panel_col] - excess_intervals[meter_col]\n",
    "    ```\n",
    "\n",
    "3. **Aggregating Excess Energy by Day:**\n",
    "    We then aggregate this \"excess energy\" for each day to get a daily summary of excess energy production.\n",
    "    ```python\n",
    "    daily_excess = excess_intervals.groupby(excess_intervals['TimePeriodStart'].dt.date)['Excess'].sum()\n",
    "    ```\n",
    "\n",
    "4. **Visualization:**\n",
    "    A bar chart provides a visual representation of the excess energy produced each day. This helps in quickly identifying days with higher excess energy production.\n",
    "    ```python\n",
    "    daily_excess.plot(kind='bar', color='skyblue')\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_calculate_net(data, meter_col, solar_panel_col):\n",
    "    # Calculate the net energy for each interval (positive or negative)\n",
    "    data['Net'] = data[solar_panel_col] - data[meter_col]\n",
    "\n",
    "    # Aggregate this \"net energy\" for each day\n",
    "    daily_data = data.groupby(data['TimePeriodStart'].dt.date).agg({meter_col: 'sum', solar_panel_col: 'sum', 'Net': 'sum'}).reset_index()\n",
    "\n",
    "    # Aggregate the monthly consumption, production, and net balance\n",
    "    monthly_data = data.groupby(data['TimePeriodStart'].dt.to_period(\"M\")).agg({meter_col: 'sum', solar_panel_col: 'sum', 'Net': 'sum'}).reset_index()\n",
    "\n",
    "    # Print out the monthly summaries\n",
    "    for index, row in monthly_data.iterrows():\n",
    "        month = row['TimePeriodStart'].strftime('%B %Y')\n",
    "        print(f\"Month: {month}\")\n",
    "        print(f\"Monthly Consumption for {meter_col}: {row[meter_col]:.2f} kWh\")\n",
    "        print(f\"Monthly Production from {solar_panel_col}: {row[solar_panel_col]:.2f} kWh\")\n",
    "        print(f\"Net Balance (Production - Consumption) for {meter_col}: {row['Net']:.2f} kWh\")\n",
    "        print('---')\n",
    "\n",
    "    # Plot using a stacked area chart for daily data\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.stackplot(daily_data['TimePeriodStart'], daily_data[meter_col], daily_data['Net'], labels=['Consumption', 'Net Production (Excess/Deficit)'], colors=['orange', 'skyblue'], alpha=0.7)\n",
    "    \n",
    "    plt.title(f'Daily Consumption and Net Solar Production for {meter_col}')\n",
    "    plt.ylabel('Energy (kWh)')\n",
    "    plt.xlabel('Date')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print out total net energy\n",
    "    total_net_energy = daily_data['Net'].sum()\n",
    "    print(f\"Total Net Energy for {meter_col}: {total_net_energy:.2f} kWh\")\n",
    "\n",
    "# Ensure the solar panel column exists in the data\n",
    "for meter, solar_panel in pods.items():\n",
    "    if solar_panel[1] in processed_data.columns:\n",
    "        plot_and_calculate_net(processed_data, meter, solar_panel[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_calculate_excess(data, meter_col, solar_panel_col):\n",
    "    # Filter intervals with excess production\n",
    "    excess_intervals = data[data[solar_panel_col] > data[meter_col]]\n",
    "\n",
    "    # Calculate the excess energy for each interval\n",
    "    excess_intervals['Excess'] = excess_intervals[solar_panel_col] - excess_intervals[meter_col]\n",
    "\n",
    "    # Aggregate this \"excess energy\" for each day\n",
    "    daily_data = excess_intervals.groupby(excess_intervals['TimePeriodStart'].dt.date).agg({meter_col: 'sum', 'Excess': 'sum'}).reset_index()\n",
    "\n",
    "    # Plot using a stacked area chart\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.stackplot(daily_data['TimePeriodStart'], daily_data[meter_col], daily_data['Excess'], labels=['Consumption', 'Excess Production'], colors=['orange', 'skyblue'], alpha=0.7)\n",
    "    \n",
    "    plt.title(f'Daily Consumption and Excess Solar Production for {meter_col}')\n",
    "    plt.ylabel('Energy (kWh)')\n",
    "    plt.xlabel('Date')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print out total excess energy\n",
    "    total_excess_energy = daily_data['Excess'].sum()\n",
    "    print(f\"Total Excess Energy for {meter_col}: {total_excess_energy:.2f} kWh\")\n",
    "\n",
    "# Ensure the solar panel column exists in the data\n",
    "for meter, solar_panel in pods.items():\n",
    "    if solar_panel[1] in processed_data.columns:\n",
    "        plot_and_calculate_excess(processed_data, meter, solar_panel[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_monthly_stacked_area_chart(data, meter_col, solar_panel_col):\n",
    "    # Group data by month and sum values\n",
    "    monthly_data = data.groupby(data['TimePeriodStart'].dt.to_period(\"M\"))[[meter_col, solar_panel_col]].sum().reset_index()\n",
    "    monthly_data['TimePeriodStart'] = monthly_data['TimePeriodStart'].dt.to_timestamp()\n",
    "\n",
    "    # Calculate the monthly excess energy\n",
    "    monthly_data['Excess'] = monthly_data[solar_panel_col] - monthly_data[meter_col]\n",
    "    monthly_excess = monthly_data[['TimePeriodStart', 'Excess']]\n",
    "\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.stackplot(monthly_data['TimePeriodStart'], monthly_data[meter_col], monthly_data[solar_panel_col], labels=['Consumption', 'Production'], alpha=0.6)\n",
    "    plt.title(f'Monthly Energy Consumption vs Solar Production for {meter_col}')\n",
    "    plt.ylabel('Energy (kWh)')\n",
    "    plt.xlabel('Date')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print out monthly excess or deficit energy\n",
    "    for _, row in monthly_excess.iterrows():\n",
    "        if row['Excess'] < 0:\n",
    "            print(f\"Energy Deficit for {row['TimePeriodStart'].strftime('%B %Y')}: {-row['Excess']:.2f} kWh\")\n",
    "        else:\n",
    "            print(f\"Excess Energy for {row['TimePeriodStart'].strftime('%B %Y')}: {row['Excess']:.2f} kWh\")\n",
    "\n",
    "\n",
    "for meter, solar_panel in pods.items():\n",
    "    if solar_panel[1] in processed_data.columns:  # Ensure the solar panel column exists\n",
    "        plot_monthly_stacked_area_chart(processed_data, meter, solar_panel[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_monthly_stacked_area_chart(data, meter_col, solar_panel_col):\n",
    "    # Group data by month and sum values\n",
    "    monthly_data = data.groupby(data['TimePeriodStart'].dt.to_period(\"M\"))[[meter_col, solar_panel_col]].sum().reset_index()\n",
    "    monthly_data['TimePeriodStart'] = monthly_data['TimePeriodStart'].dt.to_timestamp()\n",
    "    \n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.stackplot(monthly_data['TimePeriodStart'], monthly_data[meter_col], monthly_data[solar_panel_col], labels=['Consumption', 'Production'], alpha=0.6)\n",
    "    plt.title(f'Monthly Energy Consumption vs Solar Production for {meter_col}')\n",
    "    plt.ylabel('Energy (kWh)')\n",
    "    plt.xlabel('Date')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for meter, solar_panel in pods.items():\n",
    "    if solar_panel[1] in processed_data.columns:  # Ensure the solar panel column exists\n",
    "        plot_monthly_stacked_area_chart(processed_data, meter, solar_panel[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_monthly_line_chart_seaborn(data, meter_col, solar_panel_col):\n",
    "    # Group data by month and sum values\n",
    "    monthly_data = data.groupby(data['TimePeriodStart'].dt.to_period(\"M\"))[[meter_col, solar_panel_col]].sum().reset_index()\n",
    "    monthly_data['TimePeriodStart'] = monthly_data['TimePeriodStart'].dt.to_timestamp()\n",
    "    \n",
    "    plt.figure(figsize=(16, 8))\n",
    "    sns.lineplot(data=monthly_data, x='TimePeriodStart', y=meter_col, label='Consumption', marker='o')\n",
    "    sns.lineplot(data=monthly_data, x='TimePeriodStart', y=solar_panel_col, label='Production', marker='o')\n",
    "    plt.title(f'Monthly Energy Consumption vs Solar Production for {meter_col}')\n",
    "    plt.ylabel('Energy (kWh)')\n",
    "    plt.xlabel('Date')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for meter, solar_panel in pods.items():\n",
    "    if solar_panel[1] in processed_data.columns:  # Ensure the solar panel column exists\n",
    "        plot_monthly_line_chart_seaborn(processed_data, meter, solar_panel[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9: Understanding Car Charger Energy Consumption\n",
    "\n",
    "The provided code snippet undertakes the adjustment of electric car charging circuit consumption patterns throughout the day. In essence, it operates in four key steps:\n",
    "\n",
    "***Adjust the Charging Circuit Consumption:*** The raw consumption data undergoes adjustments to adhere to specific thresholds depending on the time of day. For instance, between midnight and 10 AM, the charging circuit's consumption is capped at a maximum of 3kWh for every 15 minutes. Meanwhile, between 10 AM and 3 PM, the ceiling is raised to 25kWh for every 15 minutes.\n",
    "\n",
    "***Aggregate Total Consumption:*** A new column, named 'TotalConsumption', is created in the dataset. It sums the consumption values across all meters, inclusive of electric car chargers, for every row in the data.\n",
    "\n",
    "***Smooth Out the Consumption Curve:*** To manage power load between 10 AM and 3 PM, the code computes the average charging circuit consumption during these hours and distributes this value evenly. This results in a smoother, more consistent power load throughout these midday hours. Following this, the 'AdjustedTotalConsumption' is recalculated to reflect these changes.\n",
    "\n",
    "***Visualization and Calculation:*** The original and adjusted total consumptions are plotted side-by-side to allow a visual comparison. Post-visualization, the script calculates the amount of energy saved due to these adjustments during midday hours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logic Breakdown:\n",
    "\n",
    "#### 1. Seaborn Style Setting:\n",
    "- Set the style for the Seaborn plots to \"whitegrid\". This style provides a white background with a grid to aid in readability.\n",
    "\n",
    "#### 2. TimePeriodStart Conversion:\n",
    "- Convert the 'TimePeriodStart' column in `adjusted_data` to a datetime format. This ensures the data can be correctly processed as dates and times.\n",
    "\n",
    "#### 3. Extracting Date:\n",
    "- From the 'TimePeriodStart' column, extract only the date (i.e., year-month-day) and store it in a new column called 'Date'.\n",
    "\n",
    "#### 4. Group by Date and Aggregate:\n",
    "- Group the data by 'Date'.\n",
    "- Sum the 'TotalConsumption' and 'AdjustedTotalConsumption' for each date to get daily total consumption values.\n",
    "\n",
    "#### 5. Calculate Consumption Difference:\n",
    "- For each date, compute the difference between 'AdjustedTotalConsumption' and 'TotalConsumption'. This difference shows the amount of consumption that was adjusted.\n",
    "\n",
    "#### 6. Plotting:\n",
    "- Create a new figure with a size of 16x8 inches.\n",
    "- Plot the 'TotalConsumption' for each date as a bar plot. This represents the original consumption.\n",
    "- On top of the original consumption, plot the difference in consumption (the adjustment). This \"stacks\" on top of the original consumption bars and visually represents the adjustment made.\n",
    "- Set the x-axis label as 'Date', the y-axis label as 'Total Consumption (kWh)', and provide a title for the plot.\n",
    "- Rotate the x-axis labels (dates) by 45 degrees for better readability.\n",
    "- Add a legend to differentiate between original and adjusted consumption.\n",
    "\n",
    "#### 7. Show the Plot:\n",
    "- Display the created plot.\n",
    "\n",
    "#### 8. Calculate Midday Savings:\n",
    "- Filter the data to only include rows corresponding to midday hours (as defined by the `mask_midday` mask).\n",
    "- Calculate the total original consumption and total adjusted consumption for these midday hours.\n",
    "\n",
    "#### 9. Compute Saved kWh:\n",
    "- Subtract the adjusted consumption from the original consumption to determine the amount of energy saved by the adjustments made during midday hours.\n",
    "\n",
    "#### 10. Display Savings:\n",
    "- Print the saved kWh value with a formatted message indicating the total energy saved during midday hours due to the adjustments in the charging circuit consumption.\n",
    "\n",
    "In essence, this script visualizes the daily consumption of energy, comparing the original consumption to the adjusted consumption. The adjustments made (especially during midday) lead to savings in energy, which are also quantified and presented at the end.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the style for seaborn\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Convert 'TimePeriodStart' to datetime (in case it isn't already)\n",
    "adjusted_data['TimePeriodStart'] = pd.to_datetime(adjusted_data['TimePeriodStart'])\n",
    "\n",
    "# Extract date for grouping later\n",
    "adjusted_data['Date'] = adjusted_data['TimePeriodStart'].dt.date\n",
    "\n",
    "# Group by Date and sum TotalConsumption and AdjustedTotalConsumption\n",
    "daily_summary = adjusted_data.groupby('Date').agg({'TotalConsumption': 'sum', 'AdjustedTotalConsumption': 'sum'}).reset_index()\n",
    "\n",
    "# Calculate the difference to stack the bars\n",
    "daily_summary['ConsumptionDiff'] = daily_summary['AdjustedTotalConsumption'] - daily_summary['TotalConsumption']\n",
    "\n",
    "## Plotting\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "# Plotting the base (Original Total Consumption)\n",
    "sns.barplot(data=daily_summary, x='Date', y='TotalConsumption', color='skyblue', label='Original Total Consumption')\n",
    "\n",
    "# Plotting the difference (Adjusted - Original)\n",
    "sns.barplot(data=daily_summary, x='Date', y='ConsumptionDiff', bottom=daily_summary['TotalConsumption'], color='salmon', label='Adjusted Total Consumption')\n",
    "\n",
    "# Formatting the plot\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total Consumption (kWh)')\n",
    "plt.title('Comparison of Original and Adjusted Total Consumption')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate total original and adjusted consumption for midday hours\n",
    "total_original_consumption_midday = adjusted_data.loc[mask_midday, 'TotalConsumption'].sum()\n",
    "total_adjusted_consumption_midday = adjusted_data.loc[mask_midday, 'AdjustedTotalConsumption'].sum()\n",
    "\n",
    "# Calculate saved kWh again\n",
    "saved_kwh = total_original_consumption_midday - total_adjusted_consumption_midday\n",
    "\n",
    "# Format the saved kWh value\n",
    "print(f\"We saved a total of {saved_kwh:.2f} kWh during the midday hours by adjusting the charging circuit consumption.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Setting the style for seaborn\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Convert 'TimePeriodStart' to datetime (in case it isn't already)\n",
    "adjusted_data['TimePeriodStart'] = pd.to_datetime(adjusted_data['TimePeriodStart'])\n",
    "\n",
    "# Extract month for grouping later\n",
    "adjusted_data['Month'] = adjusted_data['TimePeriodStart'].dt.month_name()\n",
    "\n",
    "# Group by Month and sum TotalConsumption and AdjustedTotalConsumption\n",
    "monthly_summary = adjusted_data.groupby('Month').agg({'TotalConsumption': 'sum', 'AdjustedTotalConsumption': 'sum'}).reset_index()\n",
    "\n",
    "# Calculate the difference to stack the bars\n",
    "monthly_summary['ConsumptionDiff'] = monthly_summary['AdjustedTotalConsumption'] - monthly_summary['TotalConsumption']\n",
    "\n",
    "## Plotting\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "# Plotting the base (Original Total Consumption)\n",
    "sns.barplot(data=monthly_summary, x='Month', y='TotalConsumption', color='skyblue', label='Original Total Consumption')\n",
    "\n",
    "# Plotting the difference (Adjusted - Original)\n",
    "sns.barplot(data=monthly_summary, x='Month', y='ConsumptionDiff', bottom=monthly_summary['TotalConsumption'], color='salmon', label='Adjusted Total Consumption')\n",
    "\n",
    "# Formatting the plot\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Total Consumption (kWh)')\n",
    "plt.title('Comparison of Original and Adjusted Total Consumption by Month')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate total original and adjusted consumption for midday hours\n",
    "total_original_consumption_midday = adjusted_data.loc[mask_midday, 'TotalConsumption'].sum()\n",
    "total_adjusted_consumption_midday = adjusted_data.loc[mask_midday, 'AdjustedTotalConsumption'].sum()\n",
    "\n",
    "# Calculate saved kWh again\n",
    "saved_kwh = total_original_consumption_midday - total_adjusted_consumption_midday\n",
    "\n",
    "# Format the saved kWh value\n",
    "print(f\"We saved a total of {saved_kwh:.2f} kWh during the midday hours by adjusting the charging circuit consumption.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the intra-day average consumption for both original and adjusted data\n",
    "avg_original = adjusted_data.groupby(['Hour', 'Minute'])['TotalConsumption'].mean().reset_index()\n",
    "avg_adjusted = adjusted_data.groupby(['Hour', 'Minute'])['AdjustedTotalConsumption'].mean().reset_index()\n",
    "\n",
    "# Merge the two average consumptions into a single dataframe for comparison\n",
    "intra_day_comparison = pd.merge(avg_original, avg_adjusted, on=['Hour', 'Minute'], how='inner')\n",
    "intra_day_comparison['Time'] = intra_day_comparison['Hour'].astype(str).str.zfill(2) + ':' + intra_day_comparison['Minute'].astype(str).str.zfill(2)\n",
    "intra_day_comparison.rename(columns={\"TotalConsumption\": \"Original Average Consumption\", \"AdjustedTotalConsumption\": \"Adjusted Average Consumption\"}, inplace=True)\n",
    "\n",
    "# Now, let's plot the shaded difference between the two curves\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "sns.lineplot(x='Time', y='Original Average Consumption', data=intra_day_comparison, label='Original Average Consumption', linewidth=2)\n",
    "sns.lineplot(x='Time', y='Adjusted Average Consumption', data=intra_day_comparison, label='Adjusted Average Consumption', linewidth=2)\n",
    "\n",
    "plt.fill_between(intra_day_comparison['Time'], \n",
    "                 intra_day_comparison['Original Average Consumption'], \n",
    "                 intra_day_comparison['Adjusted Average Consumption'], \n",
    "                 where=(intra_day_comparison['Adjusted Average Consumption'] < intra_day_comparison['Original Average Consumption']),\n",
    "                 color='red', alpha=0.4, label='Reduced Consumption')\n",
    "plt.fill_between(intra_day_comparison['Time'], \n",
    "                 intra_day_comparison['Original Average Consumption'], \n",
    "                 intra_day_comparison['Adjusted Average Consumption'], \n",
    "                 where=(intra_day_comparison['Adjusted Average Consumption'] > intra_day_comparison['Original Average Consumption']),\n",
    "                 color='green', alpha=0.4, label='Increased Consumption')\n",
    "\n",
    "plt.xlabel('Time of Day')\n",
    "plt.ylabel('Average Consumption (kWh)')\n",
    "plt.title('Intra-day Comparison of Original and Adjusted Average Consumption')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 10: Final Observations and Conclusions\n",
    "\n",
    "After analyzing various facets of the energy consumption data, it's essential to consolidate our findings, draw conclusions, and provide actionable insights. In this section, we'll summarize the key observations and suggest further steps or considerations.\n",
    "\n",
    "#TODO: Add final thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zengrid-analysis-poetry",
   "language": "python",
   "name": "zengrid-analysis-poetry"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
